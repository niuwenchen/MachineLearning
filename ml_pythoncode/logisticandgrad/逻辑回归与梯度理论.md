## 逻辑回归与梯度理论
### 算法分析
Logistic的权重是迭代500次之后的结果，那么无法证明算法已经达到了最优。在近似寻优总，
如何衡量算法的结果非常重要。为了便于理解，我们循序渐进的讲解如何评估算法的近似结果

*   超平面分析
*   斜率和截距分析： 初始值的震荡
*   权重收敛评估
*   算法的总体评价

(1)超平面的变化趋势

        for indx in range(lenw):
        if indx%20 ==0:
            weight = weightlist[indx]
            Y = -(double(weight[0]) + X * (double(weight[1]))) / double(weight[2])
            plt.plot(X, Y)
            plt.annotate("hplane:" + str(indx), xy=(X[99], Y[99]))

(2) 收敛评估

    axes1.plot(X[0:10], -weightmat[0:10, 0] / weightmat[0:10,2],color="blue",linewidth=1,linestyle="-")  # 截距
    axes2.plot(X[10:], -weightmat[10:, 0] / weightmat[10:, 2], color="red", linewidth=1, linestyle="-")  # 截距
    
    斜率
    axes1.plot(X[0:10],-weightmat[0:10,1]/weightmat[0:10,2],color='blue',linewidth=1,linestyle="-")
    axes2.plot(X[10:],-weightmat[10:,1]/weightmat[10:,2],color="red",linewidth=1,linestyle="-")
    
    权重
    axes1.plot(X, weightmat[:, 0], color='blue', linewidth=1, linestyle="-")
    axes1.set_ylabel('weight[0]')
    axes2.plot(X, weightmat[:, 1], color='red', linewidth=1, linestyle="-")
    axes2.set_ylabel('weight[1]')
    axes3.plot(X, weightmat[:, 2], color='green', linewidth=1, linestyle="-")
    axes3.set_ylabel('weight[2]')
    
    斜率已经平稳，但是截距并未达到平稳，还有进一步优化的能力，应该进一步增加迭代次数，是达到平稳
    

## 随机梯度下降法
步长的问题，步长取值越大，收敛就越快，这样迭代的次数少，效率高，但是很容易错过最优点，导致发散。

修改步长

     alpha= 2/(1.0+j+i)+0.001   # 修改alpha
     
算法总体评价
