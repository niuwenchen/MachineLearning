## 交叉验证：评估估计器性能

    clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)
    评估模型的超参数，例如C必须手动设置的时候，仍然有可能在测试集上过度拟合，可以调整参数直到模型执行最佳。
    为了解决这个问题: 训练在训练集上进行，之后对验证集进行评估，当实验似乎成功时，可以在测试集上进行最终评估
    K-fold CV，训练集被分成k个较小的集合。
    
    最后通过k倍交叉验证报告的绩效指标是循环中计算的平均值。这种方法在计算上可能是昂贵的，但是不会浪费太多的数据。
    
交叉验证的度量

交叉验证最简单的方法是cross_val_score

    from sklearn.model_selection import cross_val_score
    clf = svm.SVC(kernel ='linear',C=1)
    scores = cross_val_score(clf,iris.data,iris.targt,cv=5)
    print(scores)
    [0.96,1,0.96,10.96,1]
    平均分数  score.mean()

当cv参数为整数时，默认情况下cross_val_score使用KFold或StratifiedKFold策略。如果模型使用ClassifierMixin.则用后一个。

或者使用别的方式，用shuffle方式将数据集分成训练和验证，进行训练

    from sklean.model_selection import ShuffleSplit
    n_samples = iris.data.shape[0]
    cv= ShuffleSplit(n_splits=3,test_size=0.3,random_state=0)
    cross_val_score(clf,iris.data.iris.target,cv=cv)
    
        array([0.97,0.97,1])
        
训练数据的处理： 标准化，特征选择等。下面是进行标准化

    from sklearn import preprocessing

    iris = datasets.load_iris()
    X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.4, random_state=0)

    scaler = preprocessing.StandardScaler().fit(X_train)
    X_train_transformed = scaler.transform(X_train)
    print(X_train[0])
    print(X_train_transformed[0])
    
    [ 6.   3.4  4.5  1.6]
    [ 0.18206758  0.71103882  0.45664061  0.5584109 ]
    
使用Pipeline使得编写估计器更加容易。

    将一些行为串起来
    from sklearn.pipeline import make_pipeline
    clf = make_pipeline(preprocessing.StandardScaler(),svm.SVM(c=1))
    cross_val_score(clf,iris.data,iris.target,cv=cv)
    
### 交叉验证函数和多种度量方式
cross_validate 和 cross_val_score 不同在于下面
    
    允许特定的多种度量验证方式
    返回一个dict，training score，等很多信息。
    单一的评估系统:['test_score', 'fit_time', 'score_time']
    多种评估系统: ['test_<scorer1_name>', 'test_<scorer2_name>', 'test_<scorer...>', 'fit_time', 'score_time']
    
    clf = svm.SVC(kernel="rbf",C=1)
    from sklearn.model_selection import cross_val_predict
    from sklearn.metrics import accuracy_score


    predicted = cross_val_predict(clf,iris.data,iris.target,cv=10)
    print(accuracy_score(iris.target,predicted))
    
    cross_validation 已经作废了。
    

K-fold:

    import numpy as np
    from sklearn.model_selection import KFold

    X = ["a", "b", "c", "d"]
    kf = KFold(n_splits=2)
    data = np.array([[0., 0.], [1., 1.], [-1., -1.], [2., 2.]])
    label=np.array([0, 1, 0, 1])

    for train, test in kf.split(X):
        print("%s %s" % (train, test))
        X_train, X_test, y_train, y_test = data[train], data[test], label[train], label[test]
        print(X_train)
        print(X_test)
        print(y_train)
        print(y_test)
    通过这个KFold函数取出 样本的 下标，train: [2,3] train数据是下标为2，3 的数据


留一法  每次只留一个样本作为测试样本，n个样本得到n个分类器。

    作为一般规则，大多数作者和实证证据表明，5或10倍交叉验证应优于LOO。
    [1 2 3] [0]
    [0 2 3] [1]
    [0 1 3] [2]
    [0 1 2] [3]
    
LPO 留P法

    X=[1,2,3,4]
    loo=LeavePOut(p=3)
    for train,test in loo.split(X):
        print("%s %s"%(train,test))
    [3] [0 1 2]
    [2] [0 1 3]
    [1] [0 2 3]
    [0] [1 2 3]
    

随机法
    
    from sklearn.model_selection import ShuffleSplit
    X=np.range(5)
    ss=ShuffleSplit(n_splits=3,test_size=0.1,random_stats=0)
    for train,test in ss.split(x):
        print("%s  %s"%(train,test))
    
    [0 1 3 4]  [2]
    [2 1 4 3]  [0]
    [3 4 0 2]  [1]
    
分层KFold

是k折的变体:返回 分层折叠: 每个集合包含与完整集合大致相同的每个目标类别的样本百分比。

    skf = StratifiedKFold(n_splits=3)

组数据交叉验证，只是将数据以组来对待
    
时间序列数据的交叉验证

    from sklearn.model_selection import TimeSeriesSplit
    tscv = TimeSeriesSplit(n_splits=3)
    